# ğŸ§  Smart Task Manager â€“ Backend

A production-ready **Task Management Backend** built with **Node.js, Express, and Supabase**, featuring **intelligent task classification**, **audit logging**, and an **optional ML-powered enhancement**.

---

## ğŸš€ Features

- Task CRUD APIs (Create, Read, Update, Delete)
- Intelligent task classification (category & priority)
- ML-inspired weighted scoring with confidence values
- Optional LLM-based intent extraction (Ollama + LangChain)
- Audit trail for all task updates
- Pagination & filtering support
- Deployed globally on Render
- Flutter-ready REST APIs

---

## ğŸ—ï¸ Architecture

Flutter App
â†“
Node.js Backend (Express) â€” Global (Render)
â†“
ML-inspired Classification Engine
â†“
Supabase (PostgreSQL)


---

## ğŸ§  Intelligent Classification

### Global (Production)
The production system uses an **ML-inspired rule engine**:
- Feature extraction
- Weighted keyword scoring
- Confidence-based predictions
- Fully explainable outputs

Example:
```json
{
  "category": "scheduling",
  "category_confidence": 0.82,
  "priority": "high",
  "priority_confidence": 0.91
}
```

Optional ML Enhancement (Local)

An optional LLM-based intent extraction service is implemented using Ollama (Mistral).

Due to infrastructure requirements:

Rule-based system runs globally

ML service runs locally / on VM

Architecture supports seamless future ML deployment

Production is never blocked by ML availability.


ğŸ“¦ API Endpoints
POST   /api/tasks
GET    /api/tasks
GET    /api/tasks/:id
PATCH  /api/tasks/:id
DELETE /api/tasks/:id

ğŸ§ª Example Request
{
  "title": "Schedule meeting",
  "description": "Urgent meeting with team today about budget",
  "assigned_to": "Aayush"
}

ğŸ—‚ï¸ Project Structure
src/
 â”œâ”€â”€ controllers/
 â”œâ”€â”€ services/
 â”œâ”€â”€ routes/
 â”œâ”€â”€ validators/
 â”œâ”€â”€ config/
 â””â”€â”€ server.js

ğŸ” Environment Variables
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
INTENT_ML_URL=http://127.0.0.1:8001   # optional

â–¶ï¸ Run Locally
npm install
npm run dev


ğŸŒ Deployment

Backend deployed globally on Render

ML service designed for future VM deployment
